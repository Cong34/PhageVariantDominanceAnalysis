{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd6b681-8055-4d34-8a5e-032bf0387892",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio import SeqIO\n",
    "import pysam\n",
    "import os\n",
    "\n",
    "def Find_patient_information(patient_ID):\n",
    "    patient_information = [\"patient_ID\",\"patient_type\",\"IBD\",\"day\",\"month\",\"year\",\"seqID_virome\"] \n",
    "    data_frame = pd.read_csv(\"PHAGE_BUBBLE/Freeze3_metadata.csv\", header=0,\n",
    "                             dtype=str, na_values=['NA'],\n",
    "                             skip_blank_lines=True,\n",
    "                             true_values=['true'], false_values=['false'],\n",
    "                             nrows=None)\n",
    "\n",
    "    \n",
    "    patient_ID_whole_metadata = data_frame[data_frame[\"patient_ID\"] == patient_ID] # Select all the row with the patient_ID\n",
    "    selected_data = patient_ID_whole_metadata[patient_information] # select all the column within this list\n",
    "    selected_data = selected_data.dropna(subset=[\"seqID_virome\"]) # Remove all rows with 'NaN' in the SeqID column \n",
    "    return selected_data\n",
    "\n",
    "def condense_data_file_and_time(data):\n",
    "    Time_dict = {'Time': [f\"{day}-{month}-{year}\" for day, month, year in zip(data['day'], data['month'], data['year'])]}\n",
    "    File_name_dict = {'File_name': [f\"{seqID_virome}\" for seqID_virome in data['seqID_virome']]}\n",
    "    Time_dict.update(File_name_dict)\n",
    "    return Time_dict\n",
    "    \n",
    "def write_output_for_Bash_command(data, patient_ID): # take data from the condense_data_file_and_time Function\n",
    "    output_file_path = f'Time_series/Sample_output/{patient_ID}_sample_output.txt'\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        for item in data[\"seqID_virome\"]:\n",
    "            if not pd.isna(item):\n",
    "                file.write(\"%s\\n\" % item)\n",
    "    \n",
    "def Find_bamfiles(folder_path, FILE_ID):       \n",
    "    file_list = [\n",
    "        os.path.join(folder_path, filename)\n",
    "        for filename in os.listdir(folder_path)\n",
    "        if filename.startswith(tuple(FILE_ID)) and filename.endswith(\".bam\")\n",
    "    ]\n",
    "    return file_list\n",
    "\n",
    "def Find_Library_Size(Library_size_matrix):\n",
    "    data_frame = pd.read_csv(Library_size_matrix, sep='\\t')\n",
    "    Identification = data_frame.iloc[:,0]\n",
    "                \n",
    "    size_dict = {}\n",
    "    for id_value in Identification:\n",
    "        try:\n",
    "            Library_Size = data_frame.loc[data_frame['Sample_name'] == id_value, 'Libary_Size'].values[0]\n",
    "            size_dict[id_value] = Library_Size\n",
    "        except IndexError:\n",
    "            print(f\"ID '{id_value}' not found in the table.\")\n",
    "            return None\n",
    "    return size_dict\n",
    "\n",
    "def Find_contigs(filepaths):\n",
    "    contigs = []\n",
    "    for record in SeqIO.parse(filepaths, \"fasta\"):\n",
    "        contigs.append(record.id) \n",
    "    return contigs\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def Find_relative_abundance(component, Patient_ID, File_Time_dict):   \n",
    "    File_name = File_Time_dict[\"File_name\"]\n",
    "    Dict_Sample_ID = Find_Library_Size(\"PHAGE_BUBBLE/sampleSeqCounts.tsv\") # METAdata file, cannot change\n",
    "    contigs = Find_contigs(f\"PHAGE_BUBBLE/Paths/{component}_file/{component}_combined_file.fasta\") # Component file location, fixed.\n",
    "    File_name_lists = Find_bamfiles(f\"/scratch/user/pham0323/Time_series/Patient_sample/{Patient_ID}/{component}\", File_name) # location of bamfiles sorted, fixed.\n",
    "    \n",
    "    \n",
    "    dict_data = {}\n",
    "    for ID in File_name:\n",
    "        bam_files = [file_path for file_path in File_name_lists if file_path.startswith(f\"/scratch/user/pham0323/Time_series/Patient_sample/{Patient_ID}\")]\n",
    "        if ID not in dict_data:\n",
    "            dict_data[ID] = {}\n",
    "        for bam_file in bam_files:\n",
    "            if ID in bam_file:\n",
    "                # print(bam_file)\n",
    "                with pysam.AlignmentFile(bam_file, 'rb') as bamfile:               \n",
    "                    for references in bamfile.references:\n",
    "                        mapped_reads = bamfile.count(reference=references,\n",
    "                                                     read_callback=lambda read: not read.is_unmapped) \n",
    "                        genome_length = bamfile.get_reference_length(references)\n",
    "                        for id_value, library_size in Dict_Sample_ID.items():\n",
    "                            if id_value in bam_file:\n",
    "                                Library_Size = library_size  \n",
    "                            # print(f\"{references}: mapped read = {mapped_reads}\")\n",
    "                            # print(f\"Genome length = {genome_length}\")\n",
    "                        Rel_Ab = (mapped_reads * (1000000))/(Library_Size * genome_length)\n",
    "                        # print(f\"{ID}:{references}: Library_size = {Library_Size}: mapped read = {mapped_reads}: Rel_Ab = {Rel_Ab}\")     \n",
    "                        dict_data[ID][references] = Rel_Ab # Append the Relative abundance into the correct ID dictiondary in a list.\n",
    "    return dict_data\n",
    "\n",
    "def time_series(component, Patient_ID):\n",
    "    Dict_1 = condense_data_file_and_time(Find_patient_information(Patient_ID)) # Dict_1 has patient's info skimmed down, it has Filename and Time.\n",
    "    Dict_2 = Find_relative_abundance_scratch(component, Patient_ID, Dict_1)\n",
    "    # print(Dict_2)\n",
    "                # Dict_2 takes dict_1 info and create a dictionary with filename to paths to abundance.\n",
    "    time_value = Dict_1[\"Time\"]\n",
    "                # create an array of time values\n",
    "\n",
    "    # Create an array for each paths which contain abundance calculation\n",
    "    contigs = Find_contigs(f\"PHAGE_BUBBLE/Paths/{component}_file/{component}_combined_file.fasta\")\n",
    "    Paths_RAb = {}       \n",
    "    # Create a date range\n",
    "    date_range = pd.to_datetime(time_value, format='%d-%m-%Y')\n",
    "    Paths_RAb['Date'] = date_range\n",
    "    \n",
    "    Mean_list = {}\n",
    "    for contig in contigs: \n",
    "        value = [Dict_2[y][contig] for y in Dict_2.keys()]\n",
    "        Paths_RAb[contig] = value    \n",
    "        mean_number = np.mean(value)\n",
    "        Mean_list[contig] = mean_number\n",
    "        # print(f\"The mean of {contig} = {mean_number}\") \n",
    "    \n",
    "    print(Paths_RAb)\n",
    "    max_value = None\n",
    "    max_categories = None\n",
    "    \n",
    "    for category, value in Mean_list.items():\n",
    "        if max_value is None or value > max_value:\n",
    "            max_value = value\n",
    "            max_categories = category\n",
    "    print(f\"{max_categories} has the highest value at {max_value}\")\n",
    "\n",
    "    time_series_df = pd.DataFrame(Paths_RAb)\n",
    "    # print(time_series_df)\n",
    "    # Set the 'Date' column as the index for the time series\n",
    "    time_series_df.set_index('Date', inplace=True)\n",
    "    sns.set(style='whitegrid')\n",
    "    plt.figure(figsize=(12,5))\n",
    "    \n",
    "    \n",
    "    plt.rcParams['font.size'] = 18  \n",
    "    plt.rcParams['axes.labelsize'] = 18\n",
    "    plt.rcParams['axes.titlesize'] = 18\n",
    "    plt.rcParams['xtick.labelsize'] = 13\n",
    "    plt.rcParams['ytick.labelsize'] = 13\n",
    "    for contig in contigs:\n",
    "        ax = sns.lineplot(x='Date', y=contig, data=time_series_df, marker=\"o\", label=contig)\n",
    "        # Increase font size for x-axis label, and y-axis label\n",
    "    ax.set_xlabel(\"Date\")  # Adjust the fontsize as needed\n",
    "    ax.set_ylabel(\"Relative Abundance\")  # Adjust the fontsize as needed\n",
    "    plt.title(f'Time Series of Abundance from {component} and of patient {Patient_ID}')\n",
    "    plt.savefig(f\"Time_series/image/{Patient_ID}/{component}_Time_series_Patient{Patient_ID}.png\", dpi=300, bbox_inches='tight', format=\"png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec6f5b70-95fb-4ee2-b4b6-eb926d9405c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def Metadata_analysis(patient_ID):\n",
    "    patient_information = [\"patient_ID\",\"IBD\",\"day\",\"month\",\"year\", \"diagnosis\", \"FC_categories\", \"FC_categories_4\", \"inflammation\", \"flare\", \n",
    "                           \"type_flare\", \"disease_status\", \"current_medications\", \"seqID_virome\"] \n",
    "    data_frame = pd.read_csv(\"PHAGE_BUBBLE/Freeze3_metadata.csv\", header=0,\n",
    "                             dtype=str, na_values=['NA'],\n",
    "                             skip_blank_lines=True,\n",
    "                             true_values=['true'], false_values=['false'],\n",
    "                             nrows=None)\n",
    "\n",
    "    patient_ID_whole_metadata = data_frame[data_frame[\"patient_ID\"] == patient_ID]\n",
    "    selected_data = patient_ID_whole_metadata[patient_information]\n",
    "    selected_data = selected_data.dropna(subset=[\"seqID_virome\"])\n",
    "\n",
    "    \n",
    "    selected_data['FC_categories'].replace(['highly_elevated','elevated','above_normal','normal','below_LOD'],[4,3,2,1,0],inplace=True)\n",
    "    selected_data['FC_categories_4'].replace(['highly_elevated','elevated','above_normal','normal'],[4,3,2,1],inplace=True)\n",
    "    selected_data['inflammation'].replace(['inactive','active'],[0,1],inplace=True)\n",
    "    selected_data['flare'].replace(['no','yes'],[0,1],inplace=True)\n",
    "    # print(selected_data)\n",
    "    \n",
    "    \n",
    "    Dict_1 = { 'Time' : [f\"{day}-{month}-{year}\" for day, month, year in zip(selected_data['day'], selected_data['month'], selected_data['year'])]}\n",
    "    # Dict_1['diagnosis'] = [diagnosis for diagnosis in selected_data['diagnosis']]\n",
    "    Dict_1['FC_categories'] = [FC_categories for FC_categories in selected_data['FC_categories']]\n",
    "    Dict_1['FC_categories_4'] = [FC_categories_4 for FC_categories_4 in selected_data['FC_categories_4']]\n",
    "    Dict_1['inflammation'] = [inflammation for inflammation in selected_data['inflammation']]\n",
    "    Dict_1['flare'] = [flare for flare in selected_data['flare']]\n",
    "    \n",
    "    from datetime import datetime\n",
    "    Dict_1['Time'] = [datetime.strptime(date, '%d-%m-%Y') for date in Dict_1['Time']]\n",
    "\n",
    "    sorted_data_tuples = sorted(zip(*Dict_1.values()), key=lambda x: x[0])\n",
    "    \n",
    "    Dict_1 = {'Time': [item[0] for item in sorted_data_tuples], 'FC_categories': [item[1] for item in sorted_data_tuples], \n",
    "              'FC_categories_4': [item[2] for item in sorted_data_tuples], 'inflammation': [item[3] for item in sorted_data_tuples], \n",
    "              'flare': [item[4] for item in sorted_data_tuples]}\n",
    "    \n",
    "    return Dict_1\n",
    "\n",
    "def column_graph(patient):\n",
    "    data = Metadata_analysis(patient)\n",
    "    data['Time'] = pd.to_datetime(data['Time'], format='%d-%m-%Y')\n",
    "    print(data)\n",
    "    df = pd.DataFrame(data)\n",
    "    # df = df.sort_values(by = 'Time')\n",
    "    df.set_index('Time', inplace=True)\n",
    "    \n",
    "    df.plot(kind='bar', figsize=(30, 6), grid=True)\n",
    "    plt.xlabel('Time Points')\n",
    "    plt.ylabel('Values')\n",
    "    plt.title(f'Time Series Bar Graph for Different Categories of {patient}')\n",
    "    plt.legend(title='Categories')\n",
    "    # plt.savefig(f\"{patient}_Col_Graph.png\", dpi=300, bbox_inches='tight', format=\"png\")\n",
    "    # Rotate x-axis labels for better readability (optional)\n",
    "    plt.xticks(rotation=0)\n",
    "\n",
    "    # Show the graph\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab38fa9c-8c78-488a-b292-7d9973332549",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "All_patient_ID = ['230_4','282','1012A','2093A','2028A','2037A', '2064A','2065A','228','203','2036A','2032A','2056A','2057A','2066A','234','268']\n",
    "with open(\"resolved_component_name.txt\", \"r\") as file: \n",
    "    line = file.read().splitlines()\n",
    "Component = line\n",
    "# Results of the above: \n",
    "# Component = ['phage_comp_5', 'phage_comp_10', 'phage_comp_21', 'phage_comp_24', 'phage_comp_26', 'phage_comp_27', 'phage_comp_28',\n",
    "#              'phage_comp_31', 'phage_comp_45', 'phage_comp_46', 'phage_comp_65', 'phage_comp_73', 'phage_comp_76', 'phage_comp_86',\n",
    "#              'phage_comp_87', 'phage_comp_93', 'phage_comp_105', 'phage_comp_122', 'phage_comp_142']\n",
    "\n",
    "def Patient_Time_series(patient):\n",
    "    for component in Component: \n",
    "        print(component)\n",
    "        time_series(component, patient)\n",
    "        \n",
    "def Patient_Time_series_scratch(patient):\n",
    "    for component in Component: \n",
    "        print(component)\n",
    "        time_series_scratch(component, patient)\n",
    "    \n",
    "def Component_Time_series(component):\n",
    "    for patient in patient_ID_list:\n",
    "        print(patient)\n",
    "        time_series(component,patient)\n",
    "    for patient_scratch in patient_ID_list_scratch:\n",
    "        print(patient_scratch)\n",
    "        time_series_scratch(component, patient_scratch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24efa22d-1328-459f-96f9-fef27d4e7d07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
